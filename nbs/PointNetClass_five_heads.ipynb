{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from path import Path\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_sizeになるように1データの点群数を削除\n",
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        return data[:self.output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "\n",
    "        # x, y, z軸で平均を引く→各ベクトルの大きさの最大値で各要素を割る\n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return norm_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "\n",
    "        return torch.from_numpy(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "           PointSampler(1000),\n",
    "           Normalize(),\n",
    "           ToTensor()\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pcd(path):\n",
    "    pcd = o3d.io.read_point_cloud(path)\n",
    "    points = np.array(pcd.points)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Pytorch Datasetオブジェクトの作成\n",
    "\n",
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder:i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.pcd'):\n",
    "                    # PCDファイルからpcd.points読み込み\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __preproc__(self, path):\n",
    "        points = read_pcd(path)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms(points)\n",
    "        return pointcloud\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        pointcloud = self.__preproc__(pcd_path)\n",
    "        return {'pointcloud': pointcloud, 'category': self.classes[category]}\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パスを任意に変更すること!\n",
    "path = Path(\"../Data/five_pos_cls_three_head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0, 'l45': 1, 'l90': 2, 'r45': 3, 'r90': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(path)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0', 1: 'l45', 2: 'l90', 3: 'r45', 4: 'r90'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_classes = {i:cat for cat, i in train_ds.classes.items()}\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  503\n",
      "Valid dataset size:  150\n",
      "Number of classes:  5\n",
      "Sample pointcloud shape:  torch.Size([1000, 3])\n",
      "Class:  0\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[-1]['pointcloud'].size())\n",
    "print('Class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[-1]['pointcloud'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=10, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f47cb955c90>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNet(\n",
       "  (transform): Transform(\n",
       "    (input_transform): Tnet(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (feature_transform): Tnet(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (logsoftmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet = PointNet(classes=5)\n",
    "pointnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=512, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visdom を使う場合はこことtrain内のコメントアウトを外す\n",
    "# from visdom import Visdom\n",
    "\n",
    "# viz = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f, lr: %f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10, scheduler.get_lr()[0]))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "            # viz.line(X=np.array([epoch]), Y=np.array([running_loss]), win='loss', name='avg_train_loss', update='append')\n",
    "            # viz.line(X=np.array([epoch]), Y=np.array([val_acc]), win='acc', name='avg_test_acc', update='append')\n",
    "\n",
    "    # save the model\n",
    "    if save:\n",
    "        torch.save(pointnet.state_dict(), \"pnt_model_500_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch:   10 /   51], loss: 1.571, lr: 0.001000\n",
      "[Epoch: 1, Batch:   20 /   51], loss: 1.241, lr: 0.001000\n",
      "[Epoch: 1, Batch:   30 /   51], loss: 1.017, lr: 0.001000\n",
      "[Epoch: 1, Batch:   40 /   51], loss: 0.923, lr: 0.001000\n",
      "[Epoch: 1, Batch:   50 /   51], loss: 0.750, lr: 0.001000\n",
      "Valid accuracy: 48 %\n",
      "[Epoch: 2, Batch:   10 /   51], loss: 0.575, lr: 0.001000\n",
      "[Epoch: 2, Batch:   20 /   51], loss: 0.641, lr: 0.001000\n",
      "[Epoch: 2, Batch:   30 /   51], loss: 0.638, lr: 0.001000\n",
      "[Epoch: 2, Batch:   40 /   51], loss: 0.552, lr: 0.001000\n",
      "[Epoch: 2, Batch:   50 /   51], loss: 0.624, lr: 0.001000\n",
      "Valid accuracy: 83 %\n",
      "[Epoch: 3, Batch:   10 /   51], loss: 0.695, lr: 0.001000\n",
      "[Epoch: 3, Batch:   20 /   51], loss: 0.684, lr: 0.001000\n",
      "[Epoch: 3, Batch:   30 /   51], loss: 0.623, lr: 0.001000\n",
      "[Epoch: 3, Batch:   40 /   51], loss: 0.446, lr: 0.001000\n",
      "[Epoch: 3, Batch:   50 /   51], loss: 0.347, lr: 0.001000\n",
      "Valid accuracy: 89 %\n",
      "[Epoch: 4, Batch:   10 /   51], loss: 0.434, lr: 0.001000\n",
      "[Epoch: 4, Batch:   20 /   51], loss: 0.346, lr: 0.001000\n",
      "[Epoch: 4, Batch:   30 /   51], loss: 0.438, lr: 0.001000\n",
      "[Epoch: 4, Batch:   40 /   51], loss: 0.433, lr: 0.001000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f1f4465b66b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mproc_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"proc_time: {proc_time:.3f}sec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1b92b2fa2932>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epochs, save)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpointnetloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm3x3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm64x64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train(pointnet, train_loader, valid_loader, save=False)\n",
    "proc_time = time.time() - start\n",
    "print(f\"proc_time: {proc_time:.3f}sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet(classes=5)\n",
    "pointnet.load_state_dict(torch.load('pnt_model_500_3.pth'))\n",
    "pointnet.to(device)\n",
    "pointnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
    "                   \n",
    "        inputs, labels = data['pointcloud'].to(device).float(), data['category']\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_preds += list(preds.cpu().numpy())\n",
    "        all_labels += list(labels.numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(1, 1000, 3).to(device)\n",
    "\n",
    "dummy_out, dummy_3x3, dummy_64x64 = pointnet(dummy.transpose(1, 2))\n",
    "print(f\"output: {dummy_out}\\n\")\n",
    "print(f\"m3x3: {dummy_3x3}\\n\")\n",
    "print(f\"m64x64: {dummy_64x64}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# model = PointNet(classes=5)\n",
    "# make_dot((dummy_out, dummy_3x3, dummy_64x64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pointnet.eval()\n",
    "test_batch = next(iter(valid_loader))\n",
    "test_inputs = test_batch['pointcloud']\n",
    "test_inputs = test_inputs.to(device).float()\n",
    "# print(test_inputs)\n",
    "labels = test_batch['category']\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs, __, __ = pointnet(test_inputs.transpose(1,2))\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "# convert data\n",
    "test_inputs = list(test_inputs.cpu().numpy())\n",
    "preds = list(preds.cpu().numpy())\n",
    "labels = list(labels.cpu().numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "fig.suptitle('10 subplots')\n",
    "\n",
    "for i, test_input, label, pred in zip(range(1, 11), test_inputs, labels, preds):\n",
    "    points = np.array(test_input)\n",
    "    X = points[:, 0]\n",
    "    Y = points[:, 1]\n",
    "    Z = points[:, 2]\n",
    "    ax = fig.add_subplot(2, 5, i, projection='3d')\n",
    "    # elevはz軸方向から見た仰角，azimはx, y軸方向の方位角を指定．\n",
    "    ax.view_init(elev=100, azim=270)\n",
    "    ax.scatter3D(X, Y, Z, s=1)\n",
    "    ax.set_title(f\"GT:{inv_classes[int(label)]}\\nPred:{inv_classes[int(pred)]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_acc_train(model, train_loader, val_loader=None,  epochs=15):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            val_optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            val_optimizer.step()\n",
    "            val_scheduler.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    # print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f, lr: %f' %\n",
    "                    #     (epoch + 1, i + 1, len(train_loader), running_loss / 10, scheduler.get_lr()[0]))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            if epoch == 14:\n",
    "                print('Valid accuracy: %d %%' % val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     print(f'iter: {i}')\n",
    "#     val_optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "#     val_scheduler = torch.optim.lr_scheduler.StepLR(val_optimizer, step_size=128, gamma=0.1)\n",
    "    # val_acc_train(pointnet, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample\n",
    "# inv_classes\n",
    "# {0: '0', 1: 'l45', 2: 'l90', 3: 'r45', 4: 'r90'}\n",
    "\n",
    "pathes = ['../Data/five_position_classes_head/r90/valid/0.pcd', '../Data/five_position_classes_head/l90/valid/0.pcd', \n",
    "        '../Data/five_position_classes_head/r45/valid/0.pcd', '../Data/five_position_classes_head/l45/valid/0.pcd',\n",
    "        '../Data/five_position_classes_head/0/valid/0.pcd']\n",
    "labels = [4, 2, 3, 1, 0]\n",
    "\n",
    "samples = []\n",
    "for path in pathes:\n",
    "    points = read_pcd(path)\n",
    "    samples.append(points)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "fig.suptitle('5 samples')\n",
    "\n",
    "for i, sample, label in zip(range(1, 6), samples, labels):\n",
    "    points = np.array(sample)\n",
    "    X = points[:, 0]\n",
    "    Y = points[:, 1]\n",
    "    Z = points[:, 2]\n",
    "    ax = fig.add_subplot(2, 5, i, projection='3d')\n",
    "    # elevはz軸方向から見た仰角，azimはx, y軸方向の方位角を指定．\n",
    "    ax.view_init(elev=100, azim=270)\n",
    "    ax.scatter3D(X, Y, Z, s=1)\n",
    "    ax.set_title(f\"{inv_classes[label]}\")\n",
    "    ax.set_zticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet.eval()\n",
    "test_inputs = [Normalize()(sample) for sample in samples]\n",
    "test_inputs = torch.from_numpy(np.array(test_inputs))\n",
    "test_inputs = test_inputs.to(device).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs, __, __ = pointnet(test_inputs.transpose(1,2))\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "# convert data\n",
    "test_inputs = list(test_inputs.cpu().numpy())\n",
    "preds = list(preds.cpu().numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(16, 40))\n",
    "fig.suptitle('5 predicts', fontsize='xx-large')\n",
    "\n",
    "for i, test_input, label, pred in zip(range(1, 6), samples, labels, preds):\n",
    "    points = np.array(test_input)\n",
    "    X = points[:, 0]\n",
    "    Y = points[:, 1]\n",
    "    Z = points[:, 2]\n",
    "    ax = fig.add_subplot(5, 2, i, projection='3d')\n",
    "    # elevはz軸方向から見た仰角，azimはx, y軸方向の方位角を指定．\n",
    "    ax.view_init(elev=100, azim=270)\n",
    "    ax.scatter3D(X, Y, Z, s=1)\n",
    "    ax.set_title(f\"Label:{inv_classes[int(label)]}\\nPred:{inv_classes[int(pred)]}\", fontsize='xx-large')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "    ax.set_xlabel(\"X\", fontsize='xx-large')\n",
    "    ax.set_ylabel(\"Y\", fontsize='xx-large')\n",
    "    ax.set_zlabel(\"Z\", fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-0.05, 1.5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}