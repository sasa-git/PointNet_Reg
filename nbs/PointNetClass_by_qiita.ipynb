{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "display_name": "Python 3.7.9 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "48fd179440322e061cbc970dcdf365600b1385398598600899ab36021fced37c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://qiita.com/opeco17/items/707a5c57bca41a145122"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinear(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(NonLinear, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_channels, self.output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(self.output_channels))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self, num_channels, num_points):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_points = num_points\n",
    "        self.main = nn.MaxPool1d(self.num_points)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = input.view(-1, self.num_channels, self.num_points)\n",
    "        out = self.main(out)\n",
    "        out = out.view(-1, self.num_channels)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTNet(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super().__init__()\n",
    "        self.num_points = num_points\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            NonLinear(3, 64),\n",
    "            NonLinear(64, 128),\n",
    "            NonLinear(128, 1024),\n",
    "            MaxPool(1024, self.num_points),\n",
    "            NonLinear(1024, 512),\n",
    "            NonLinear(512, 256),\n",
    "            nn.Linear(256, 9)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        matrix = self.main(input).view(-1, 3, 3)\n",
    "        out = torch.matmul(input.view(-1, self.num_points, 3), matrix)\n",
    "        out = out.view(-1, 3)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTNet(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(FeatureTNet, self).__init__()\n",
    "        self.num_points = num_points\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            NonLinear(64, 64),\n",
    "            NonLinear(64, 128),\n",
    "            NonLinear(128, 1024),\n",
    "            MaxPool(1024, self.num_points),\n",
    "            NonLinear(1024, 512),\n",
    "            NonLinear(512, 256),\n",
    "            nn.Linear(256, 4096)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        matrix = self.main(input).view(-1, 64, 64)\n",
    "        out = torch.matmul(input.view(-1, self.num_points, 64), matrix)\n",
    "        out = out.view(-1, 64)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_points, num_labels):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            InputTNet(self.num_points),\n",
    "            NonLinear(3, 64),\n",
    "            NonLinear(64, 64),\n",
    "            FeatureTNet(self.num_points),\n",
    "            NonLinear(64, 64),\n",
    "            NonLinear(64, 128),\n",
    "            NonLinear(128, 1024),\n",
    "            MaxPool(1024, self.num_points),\n",
    "            NonLinear(1024, 512),\n",
    "            nn.Dropout(p=0.3),\n",
    "            NonLinear(512, 256),\n",
    "            nn.Dropout(p=0.3),\n",
    "            NonLinear(256, self.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampler(batch_size, num_points):\n",
    "    half_batch_size = int(batch_size/2)\n",
    "    normal_sampled = torch.randn(half_batch_size, num_points, 3)\n",
    "    uniform_sampled = torch.rand(half_batch_size, num_points, 3)\n",
    "    normal_labels = torch.ones(half_batch_size)\n",
    "    uniform_labels = torch.zeros(half_batch_size)\n",
    "\n",
    "    input_data = torch.cat((normal_sampled, uniform_sampled), dim=0)\n",
    "    labels = torch.cat((normal_labels, uniform_labels), dim=0)\n",
    "\n",
    "    data_shuffle = torch.randperm(batch_size)\n",
    "\n",
    "    return input_data[data_shuffle].view(-1, 3), labels[data_shuffle].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration: 0    Loss: 0.6403641700744629\n",
      "Iteration: 0    Accuracy: 0.578125\n",
      "Iteration: 10    Loss: 0.34747737646102905\n",
      "Iteration: 10    Accuracy: 1.0\n",
      "Iteration: 20    Loss: 0.3266719877719879\n",
      "Iteration: 20    Accuracy: 1.0\n",
      "Iteration: 30    Loss: 0.3157070279121399\n",
      "Iteration: 30    Accuracy: 1.0\n",
      "Iteration: 40    Loss: 0.31111931800842285\n",
      "Iteration: 40    Accuracy: 1.0\n",
      "Iteration: 50    Loss: 0.3056040406227112\n",
      "Iteration: 50    Accuracy: 1.0\n",
      "Iteration: 60    Loss: 0.3026292026042938\n",
      "Iteration: 60    Accuracy: 1.0\n",
      "Iteration: 70    Loss: 0.3026331663131714\n",
      "Iteration: 70    Accuracy: 1.0\n",
      "Iteration: 80    Loss: 0.299703449010849\n",
      "Iteration: 80    Accuracy: 1.0\n",
      "Iteration: 90    Loss: 0.29401636123657227\n",
      "Iteration: 90    Accuracy: 1.0\n",
      "Iteration: 100    Loss: 0.28994905948638916\n",
      "Iteration: 100    Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "\n",
    "batch_size = 64\n",
    "num_points = 64\n",
    "num_labels = 1\n",
    "\n",
    "pointnet = PointNet(num_points, num_labels)\n",
    "\n",
    "new_param = pointnet.state_dict()\n",
    "new_param['main.0.main.6.bias'] = torch.eye(3, 3).view(-1)\n",
    "new_param['main.3.main.6.bias'] = torch.eye(64, 64).view(-1)\n",
    "pointnet.load_state_dict(new_param)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for iteration in range(100+1):\n",
    "\n",
    "    pointnet.zero_grad()\n",
    "    input, labels = data_sampler(batch_size, num_points)\n",
    "\n",
    "    output = pointnet(input)\n",
    "    output = nn.Sigmoid()(output)\n",
    "\n",
    "    error = criterion(output, labels)\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output[output > 0.5] = 1\n",
    "        output[output < 0.5] = 0\n",
    "        accuracy = (output==labels).sum().item()/batch_size\n",
    "\n",
    "    loss_list.append(error.item())\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    if iteration % 10 == 0:\n",
    "        print(f'Iteration: {iteration}    Loss: {error.item()}')\n",
    "        print(f'Iteration: {iteration}    Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input.size(): torch.Size([4096, 3])\nlabels.size(): torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "input, labels = data_sampler(batch_size, num_points)\n",
    "print(f'input.size(): {input.size()}')\n",
    "print(f'labels.size(): {labels.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}